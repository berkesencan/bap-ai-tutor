CSCI-UA.0480-051: Parallel Computing Midterm Exam (Oct
19th, 2021)
Your Name
Total: 100 points
Important Notes - READ BEFORE SOLVING THE EXAM
• If you perceive any ambiguity in any of the questions, state your assumptions clearly and solve the
problem based on your assumptions. We will grade both your solutions and your assumptions.
• This exam is take-home.
• The exam is posted, on Brightspace, at the beginning of the Oct 19th lecture.
• You have up to 23 hours and 55 minutes from the beginning of the Oct 19th lecture to submit on
Brightspace (in the assignments section).
• You are allowed only one submission, unlike assignments and labs.
• Your answers must be very focused. You may be penalized for wrong answers and for putting
irrelevant information in your answers.
• You must upload a pdf file.
• Your answer sheet must have a cover page (as indicated below) and one problem answer per page
(e.g. problem 1 in separate page, problem 2 in another separate page, etc).
• This exam has 4 problems totaling 100 points.
• The very first page of your answer is the cover page and must contain:
– Your Last Name
– Your First Name
– Your NetID
– Copy and paste the honor code shown in the rectangle at the bottom of this page.
Honor code (copy and paste what is typed in red below, to the first page of your exam)
• You may use the textbook, slides, and any notes you have. But you may not use the internet.
• You may NOT use communication tools to collaborate with other humans. This includes but is
not limited to G-Chat, Messenger, E-mail, etc.
• Do not try to search for answers on the internet it will show in your answer, and you will earn an
immediate grade of 0.
• Anyone found sharing answers or communicating with another student during the exam period will
earn an immediate grade of 0.
• “I understand the ground rules and agree to abide by them. I will not share answers or assist
another student during this exam, nor will I seek assistance from another student or attempt to
view their answers.”

1

Problem 1
Assume we have the following task flow graph where every node is a task and an arrow
from a task to another means dependencies. For example, task F cannot start before task E
is done.
Suppose we have two types of cores: type A and type B. The following table shows the
time taken by each task, in nano seconds, if executed on a core of type A and if executed
on a core of type B.
Task
Time Taken on
core type A
Time Taken on
core type B
E
F
G
H
I
8
12
18
6
11
7
9
22
4
6
a. [5 points] If we use all cores of type A, what will be the span (indicate tasks and total
time) of the DAG?
b. [5 points] If we use all cores of type B, what will be the span (indicate tasks and
total time) of
the DAG?
c. [15 points] What will be the smallest number of cores, of any type, that gives the
best speedup
compared to using a single core of type A? You can use a mix of any cores (e.g. two cores
of type A and one core of type B, etc). In your solution, indicate which task will run on
which core, the total number of cores you will use for each type, the total execution times
(for parallel version and the sequential version running on core of type A), and the
speedup (relative to sequential execution on core of type A).
d. [10 points] Suppose we use only cores of type A. What is the smallest number of
cores to get
the highest speedup? Calculate that speedup. Then, if you are allowed to remove only one
arrow from the DAG, while keeping the DAG a legal one, what will be that arrow to give
a better speedup than the one you just calculated? If there are several solutions, pick one
solution, and calculate the new speedup. If there are no solutions, state so, and give no more than
two lines of explanation as to why there is no solution.

Problem 2
a. [5 points] For each one of the following designs, indicate whether it is SISD, SIMD,
MISD,
or MIMD. No justification needed. Note: If the design fits more than one category, then
pick the more general one. For example, MIMD can execute as SIMD if all the
instructions are the same. The more general is MIMD so pick MIMD not SIMD.
1. A single core processor with a single instruction stream and a single data stream.
2. A vector processor executing the same instruction on multiple data elements simultaneously.
2

3. A hypothetical processor that executes multiple instructions on the same data stream.
4. A multi-core processor with each core executing independent instruction streams.
5. A many-core processor where some cores have SIMD capabilities while others execute
independently.
b. [5 points] Indicate whether each statement below is true (T) or false (F). No justification
needed.
1. Hyperthreading allows a single core to execute multiple threads concurrently.
2. Superscalar processors can execute multiple instructions simultaneously in a single
cycle.
3. Speculative execution improves performance by predicting the outcome of branches.
4. Cache coherence ensures that all cores see the same data in a shared memory system.
5. In a distributed memory system, processes communicate by message passing.
c. [5 points] If we have a multicore processor with twelve cores, and four-way hyperthreading
each, what is the largest number of threads that can execute at the same time? Explain
your answer with no more than two sentences.

Problem 3
a. Suppose you have an algorithm with six tasks that can be executed in parallel.
1. [6 points] What are the characteristics of those tasks that can make you decide to
implement the program as one process with six threads as opposed to six
processes with one thread each? State two characteristics to get full credit.
2. [4 points] With six parallel tasks, it may seem that six cores will give the best speedup
over sequential code. However, there may be cases where less than six cores can
give the same speedup as the six cores. Give a brief description of such a case in
no more than 2-3 lines.
b. [4 points] If we have two implementations of the same algorithm and we found that
one
implementation has higher efficiency than the other. Does that always mean that the
implementation with higher efficiency will always be faster? Justify in two sentences.
c. We have two different implementations of the same algorithm. The first
implementation has three million instructions where one third are floating point
instructions, and two thirds are integer instructions. The second implementation has
five million instructions where all of them are integer instructions. Suppose a floatingpoint instruction
takes 12 cycles while an integer instruction takes two cycles. We execute
these two implementations on a 3GHz machine. Assume single core processor, where this
core is SISD.
1. [6 points] What is the MIPS of each implementation?
2. [6 points] What is the CPI of each implementation?
3. [6 points] What is the total execution time of each implementation?
4. [8 points] State which implementation is better based on each of the following
measurements: instruction count, MIPS, CPI, and execution time.

Problem 4
For problem 4, assume we have one communicator: MPI COMM WORLD.
Suppose we have eight processes. Each process has two arrays, of ten integers each, C
and D. D is declared as int D[10 points] but is not initialized and C is initialized as follows:
process 0-7: int C[10 points] = i*10, i*10+1, i*10+2, i*10+3, i*10+4, i*10+5, i*10+6, i*10+7,
i*10+8, i*10+9; (where i is the process rank)
a. [3 points] Write one MPI command that, if executed by all the eight processes, the
D arrays at
each process will be:
process 0-7: int D[10 points] = 280, 281, 282, 283, 284, 285, 286, 287, 288, 289;

3

b. [3 points] Write one MPI command that, if executed by all the eight processes, the
C arrays at
each process will be:
process 0-7: int C[10 points] = 70, 71, 72, 73, 74, 75, 76, 77, 78, 79;
c. [4 points] Why MPI Reduce() requires a reduction operation as an argument while
MPI Allgather() does not?

4

