{"success":true,"data":{"text":"**Parallel Computing Practice Exam**\n\n**Name:** _________________________\n**Date:** _________________________\n\n\n**Section 1: Multiple Choice (1 point each)**\n\n1.  Which of the following is NOT a primary challenge in parallel computing?\n    a)  Load balancing\n    b)  Data dependency\n    c)  Increased processing speed\n    d)  Communication overhead\n\n\n    Answer: _____________\n\n\n2.  What is Amdahl's Law used to calculate?\n    a)  The maximum speedup achievable by parallelizing a program\n    b)  The optimal number of processors for a given problem\n    c)  The communication overhead in a parallel system\n    d)  The memory bandwidth of a parallel system\n\n\n    Answer: _____________\n\n\n**Section 2: Short Answer (3 points each)**\n\n3. Briefly explain the difference between shared memory and distributed memory parallel architectures.  Include at least one advantage and one disadvantage of each.\n\n\nAnswer:\n\n\n\n4. Describe two common techniques used for handling race conditions in parallel programs.\n\n\nAnswer:\n\n\n\n**Section 3: Problem Solving (5 points)**\n\n5. Consider the following task:  Sorting a list of 1,000,000 integers.  Describe how you would approach this problem using a parallel algorithm.  Specifically:\n\n*   What parallel programming paradigm would you choose (e.g., shared memory, message passing)? Justify your choice.\n*   What algorithm would you use for sorting? Explain why it is suitable for parallel processing.\n*   Briefly outline the steps involved in parallelizing the algorithm.  Consider load balancing and data distribution.\n\n\nAnswer:\n\n\n\n\n\n\n**Answer Key:**\n\n1.  c) Increased processing speed\n2.  a) The maximum speedup achievable by parallelizing a program\n3.  See expected answer below\n4. See expected answer below\n5. See expected answer below\n\n\n**Expected Answers:**\n\n**3. Shared Memory vs. Distributed Memory:**\n\n*   **Shared Memory:**  Processors share a common address space.  Advantage: Easier programming model, simpler data sharing. Disadvantage: Scalability limitations, potential for memory contention.\n*   **Distributed Memory:** Processors have their own private memory.  Advantage: Better scalability, less memory contention. Disadvantage: More complex programming (message passing), more overhead for data communication.\n\n\n**4. Handling Race Conditions:**\n\nTwo common techniques are:\n\n*   **Mutual Exclusion (Mutexes):**  A lock that allows only one thread to access a shared resource at a time.\n*   **Semaphores:**  A more generalized synchronization primitive that allows for controlling access to a resource based on a counter.\n\n\n**5. Parallelizing Sorting:**\n\n*   **Paradigm:** Shared memory would be suitable for this problem, as it simplifies data sharing between threads.  However, for extremely large datasets, a distributed memory approach might be necessary.  The choice depends on the available resources.\n\n*   **Algorithm:** Merge Sort is a good choice for parallel sorting. It recursively divides the list into smaller sublists that can be sorted independently. This inherent divide-and-conquer nature maps well to parallel processing.  Other algorithms like Quicksort can also be parallelized, but their performance can be less predictable due to potential load imbalances.\n\n*   **Steps:**\n    1. Divide the list of integers into smaller sublists, one for each processor.\n    2. Each processor independently sorts its sublist using a sequential sorting algorithm (e.g., merge sort).\n    3. Merge the sorted sublists together using a parallel merge algorithm.  This step may require communication between processors to exchange data.\n    4. Load balancing can be achieved by dynamically assigning sublists of roughly equal size to each processor.\n\n\nThis answer key provides a framework; variations in approach are possible and should be evaluated on their merits.  The quality of the student's explanation and justification is key to awarding full points.\n","usageMetadata":{"promptTokenCount":59,"candidatesTokenCount":829,"totalTokenCount":888,"promptTokensDetails":[{"modality":"TEXT","tokenCount":59}],"candidatesTokensDetails":[{"modality":"TEXT","tokenCount":829}]},"pdfDownloadUrl":"/api/ai/download-pdf/practice-exam-Parallel-Computing-1750984319194.pdf","pdfGenerated":true}}