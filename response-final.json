{"success":true,"data":{"questions":{"text":"1. **Core Selection and Speedup:** You are designing a parallel program with three tasks: Task 1 (execution time 20ms), Task 2 (execution time 15ms), Task 3 (execution time 25ms).  You have two types of cores available:\n\n| Core Type | Task 1 (ms) | Task 2 (ms) | Task 3 (ms) |\n|---|---|---|---|\n| Core A | 20 | 15 | 25 |\n| Core B | 15 | 10 | 20 |\n\na)  If you use only Core A, what is the total execution time and the speedup compared to a single Core A?\n\nb) If you use only Core B, what is the total execution time and the speedup compared to a single Core A?\n\nc)  What is the optimal combination of Core A and Core B (number of each core type) to achieve the maximum speedup compared to using a single Core A? Show your task assignment to each core.  Calculate the total execution time for this optimal configuration and its speedup.\n\n\n2. **MIMD Classification and Hyperthreading:** Classify each of the following multicore processor designs as either SISD, SIMD, MISD, or MIMD. Briefly justify your answer in one sentence for each.\n\na) A single core with superscalar capabilities and speculative execution, but without hyperthreading.\n\nb) A multicore chip where each core has only pipelining capabilities.  \n\nc) A multicore chip with eight cores, each with two-way hyperthreading, executing independent processes simultaneously.\n\n\n3. **MPI Communication:** Four processes (P0, P1, P2, P3) each have an integer array `A` of size 5, initialized as follows:\n\nP0: A = {1, 2, 3, 4, 5}\nP1: A = {6, 7, 8, 9, 10}\nP2: A = {11, 12, 13, 14, 15}\nP3: A = {16, 17, 18, 19, 20}\n\nEach process also has an array `B` of size 5, initially uninitialized.  Write a single MPI command (using MPI_Sendrecv, MPI_Allgather, MPI_Bcast, MPI_Reduce or a combination if needed) to achieve the following:\n\na)  All processes will have `B` equal to  {1, 2, 3, 4, 5} after execution of the command.\n\n\nb) All processes will have `B` equal to {55, 55, 55, 55, 55} (sum of all A arrays) after the execution of the command. Note that there is no need to use MPI_Reduce directly here.  You may use other commands if necessary.\n","usageMetadata":{"promptTokenCount":1791,"candidatesTokenCount":641,"totalTokenCount":2432,"promptTokensDetails":[{"modality":"DOCUMENT","tokenCount":1290},{"modality":"TEXT","tokenCount":501}],"candidatesTokensDetails":[{"modality":"TEXT","tokenCount":641}]}},"parsedQuestions":[],"questionPoints":[30,35,35],"subject":"Parallel Computing","difficulty":"medium","pdfPath":"/Users/berkesencan/Desktop/bap-ai-tutor-main/backend/uploads/practice-exam-1751410338766.pdf"}}